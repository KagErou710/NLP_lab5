{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
    "\n",
    "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set GPU device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       "  'idx': Value(dtype='int32', id=None)},\n",
       " {'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "mnli['train'].features, snli['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import datasets\n",
    "# from datasets import ClassLabel\n",
    "\n",
    "# dataset_file = r\"C:\\Users\\Tairo Kageyama\\Documents\\GitHub\\Python-fo-Natural-Language-Processing-main\\lab5\\snli_1.0\\snli_1.0\\snli_1.0_train_test.jsonl\"\n",
    "\n",
    "# premise = []\n",
    "# hypothesis = []\n",
    "# label = []\n",
    "\n",
    "# with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     for line in f:\n",
    "#         data = json.loads(line)\n",
    "#         premise.append(data[\"sentence1\"])\n",
    "#         hypothesis.append(data[\"sentence2\"])\n",
    "#         label.append(data[\"gold_label\"])\n",
    "\n",
    "# features = {\n",
    "#     \"premise\": premise,\n",
    "#     \"hypothesis\": hypothesis,\n",
    "#     \"label\": label\n",
    "# }\n",
    "\n",
    "# custom_dataset = datasets.Dataset.from_dict(features)\n",
    "\n",
    "# custom_dataset.features['label'] = ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)\n",
    "\n",
    "# custom_dataset.features\n",
    "\n",
    "# # custom_dataset = custom_dataset.map(lambda example: {\"label\": example[\"label\"]}, features=datasets.Features({\"label\": ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)}))\n",
    "# # custom_dataset = custom_dataset.map(lambda example: {\"premise\": example[\"premise\"], \"hypothesis\": example[\"hypothesis\"]})\n",
    "# # custom_dataset.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of datasets to remove 'idx' column from\n",
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'idx' column from each dataset\n",
    "for column_names in mnli.column_names.keys():\n",
    "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have your two DatasetDict objects named snli and mnli\n",
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
    "})\n",
    "#remove .select(list(range(1000))) in order to use full dataset\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_seq_length = 128\n",
    "    padding = 'max_length'\n",
    "    # Tokenize the premise\n",
    "    premise_result = tokenizer(\n",
    "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    print(premise_result)\n",
    "    #num_rows, max_seq_length\n",
    "    # Tokenize the hypothesis\n",
    "    hypothesis_result = tokenizer(\n",
    "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    #num_rows\n",
    "    return {\n",
    "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
    "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
    "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
    "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise_input_ids': tensor([ 101, 2092, 2027, 1005, 2128, 4795,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'premise_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'hypothesis_input_ids': tensor([ 101, 2027, 3749, 2498, 2000, 4737, 2055, 1012,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'hypothesis_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(2)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'], \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start from a pretrained bert-base-uncased model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function\n",
    "\n",
    "## Classification Objective Function \n",
    "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
    "\n",
    "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
    "\n",
    "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
    "\n",
    "## Regression Objective Function. \n",
    "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
    "\n",
    "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)\n",
    "\n",
    "<img src=\"./figures/sbert-architecture.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "    \n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/sbert-ablation.png\" width=\"350\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()\n",
    "\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler_classifier.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# num_epoch = 2\n",
    "# # 1 epoch should be enough, increase if wanted\n",
    "# for epoch in range(num_epoch):\n",
    "#     model.train()  \n",
    "#     classifier_head.train()\n",
    "#     # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "#     for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
    "#         # zero all gradients on each new step\n",
    "#         optimizer.zero_grad()\n",
    "#         optimizer_classifier.zero_grad()\n",
    "        \n",
    "#         # prepare batches and more all to the active device\n",
    "#         inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "#         inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "#         attention_a = batch['premise_attention_mask'].to(device)\n",
    "#         attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "#         label = batch['labels'].to(device)\n",
    "        \n",
    "#         # extract token embeddings from BERT at last_hidden_state\n",
    "#         u = model(inputs_ids_a, attention_mask=attention_a)  \n",
    "#         v = model(inputs_ids_b, attention_mask=attention_b)  \n",
    "\n",
    "#         u_last_hidden_state = u.last_hidden_state # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "#         v_last_hidden_state = v.last_hidden_state # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "#          # get the mean pooled vectors\n",
    "#         u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "#         v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "        \n",
    "#         # build the |u-v| tensor\n",
    "#         uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "#         uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "        \n",
    "#         # concatenate u, v, |u-v|\n",
    "#         x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "        \n",
    "#         # process concatenated tensor through classifier_head\n",
    "#         x = classifier_head(x) #batch_size, classifer\n",
    "        \n",
    "#         # calculate the 'softmax-loss' between predicted and true label\n",
    "#         loss = criterion(x, label)\n",
    "        \n",
    "#         # using loss, calculate gradients and then optimizerize\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer_classifier.step()\n",
    "\n",
    "#         scheduler.step() # update learning rate scheduler\n",
    "#         scheduler_classifier.step()\n",
    "        \n",
    "#     print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')\n",
    "#     if epoch == num_epoch-1:\n",
    "#         torch.save(model.state_dict(), 'S-BERT.pt')\n",
    "#         torch.save(model.state_dict(), 'S-BERT.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# extract token embeddings from BERT at last_hidden_state\u001b[39;00m\n\u001b[0;32m     18\u001b[0m u \u001b[38;5;241m=\u001b[39m model(inputs_ids_a, attention_mask\u001b[38;5;241m=\u001b[39mattention_a)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# all token embeddings A = batch_size, seq_len, hidden_dim\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_ids_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_b\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# all token embeddings B = batch_size, seq_len, hidden_dim\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# get the mean pooled vectors\u001b[39;00m\n\u001b[0;32m     22\u001b[0m u_mean_pool \u001b[38;5;241m=\u001b[39m mean_pool(u, attention_a)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# batch_size, hidden_dim\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:309\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 309\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    311\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    313\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tairo Kageyama\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained = torch.load(r'C:\\Users\\Tairo Kageyama\\Documents\\GitHub\\Python-fo-Natural-Language-Processing-main\\lab5\\model\\S-BERT.pt')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.to(device)\n",
    "model.load_state_dict(trained)\n",
    "model.eval()\n",
    "classifier_head.eval()\n",
    "total_similarity = 0\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "        \n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "        v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "        # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
    "\n",
    "        similarity_score = cosine_similarity(u_mean_pool, v_mean_pool)\n",
    "        total_similarity += similarity_score\n",
    "    \n",
    "average_similarity = total_similarity / len(eval_dataloader)\n",
    "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49784118e-01  1.56582311e-01 -1.35506585e-01  2.07037881e-01\n",
      "  1.88439071e-01 -7.51025081e-02  5.41316748e-01  9.45977449e-01\n",
      " -4.87500101e-01 -8.27707112e-01  5.08777678e-01 -2.37404823e-01\n",
      "  1.30652368e-01  4.14803892e-01 -1.38623402e-01  8.38009920e-03\n",
      "  2.32306585e-01  1.02923207e-01 -2.94782400e-01 -7.64665604e-02\n",
      " -5.61421573e-01 -3.46141249e-01  1.02922425e-01  8.76278520e-01\n",
      "  4.38546479e-01  8.52520242e-02  2.18256444e-01  2.14446187e-01\n",
      "  7.51448125e-02 -1.82092443e-01  2.42360160e-01  2.31781956e-02\n",
      " -1.84453458e-01 -1.27205297e-01 -8.32326487e-02 -1.74275592e-01\n",
      " -1.35676101e-01  1.55047458e-02 -4.55836505e-01  9.12900269e-02\n",
      " -3.02345484e-01 -1.65715992e-01  1.11455202e-01 -1.75064743e-01\n",
      " -1.05880037e-01 -3.26010197e-01  9.96159464e-02  3.43973860e-02\n",
      "  4.56195742e-01 -1.00351237e-01 -4.55192626e-01  1.34634554e-01\n",
      " -2.33147651e-01 -1.15132384e-01  1.82590514e-01  4.23503816e-01\n",
      " -5.30576110e-01 -3.60495746e-01 -6.45343959e-01 -1.54923320e-01\n",
      "  2.87239105e-01  1.89003944e-02 -3.11906159e-01 -8.08036566e-01\n",
      "  1.55241922e-01  3.87661934e-01  2.43661106e-01  2.99834400e-01\n",
      " -4.73944098e-01 -2.15690434e-01 -5.01902819e-01 -3.65992337e-01\n",
      " -4.94778790e-02 -1.23013169e-01 -5.20009518e-01  2.61301279e-01\n",
      " -3.35108966e-01  2.90922392e-02  1.17556769e-02 -2.87047327e-01\n",
      " -3.19854558e-01  5.82504988e-01  2.51159910e-02  3.99605542e-01\n",
      "  1.90111995e-02  6.65679812e-01  1.23221382e-01  2.51772702e-01\n",
      " -2.10116599e-02  2.10151061e-01 -1.26370698e-01 -1.90280825e-02\n",
      " -2.14810699e-01  5.20157993e-01  3.87743235e-01 -1.00806177e-01\n",
      "  5.66980898e-01 -6.38650507e-02 -3.07682097e-01  5.26925266e-01\n",
      "  8.19061100e-02 -6.66671932e-01  5.15793383e-01 -1.40278712e-01\n",
      "  2.76742578e-01  3.91973220e-02  1.91947445e-01 -2.68051714e-01\n",
      " -1.28425479e-01  1.16063669e-01  1.10716015e-01 -2.67116189e-01\n",
      " -5.46514094e-01 -2.87438184e-01 -4.44359213e-01  5.30639827e-01\n",
      "  4.68293905e-01 -3.65984216e-02 -2.30359375e-01 -1.72929287e-01\n",
      " -2.78996468e-01  6.14781119e-02  2.25591615e-01  8.02660108e-01\n",
      " -4.48078901e-01 -1.28284812e-01 -1.11005127e-01 -9.91036817e-02\n",
      "  2.38803610e-01 -3.50362986e-01 -4.36892584e-02  3.51925552e-01\n",
      "  2.88406461e-01 -1.60447299e-01 -1.36157393e-01  1.12681612e-01\n",
      "  3.03574383e-01 -6.71366870e-01 -6.55390918e-01  2.88327783e-01\n",
      "  1.41603887e-01 -2.30663255e-01  7.27645993e-01 -1.81354374e-01\n",
      "  3.64300162e-01  8.52568671e-02  2.75084853e-01  5.10285139e-01\n",
      "  6.05454929e-02 -2.92037874e-01  3.11760277e-01 -1.26245394e-01\n",
      " -4.44120258e-01 -2.69067466e-01 -3.31434458e-01 -8.00592378e-02\n",
      " -6.39316797e-01  7.17457056e-01  9.03805569e-02  4.42374170e-01\n",
      "  2.15788007e-01  2.58369707e-02  7.84940273e-02  3.41609091e-01\n",
      " -5.41496873e-01  7.00295269e-01 -1.40143871e-01  5.70231557e-01\n",
      " -3.49123746e-01  3.92677575e-01 -1.50666401e-01  3.31614733e-01\n",
      "  1.70911640e-01 -1.68933600e-01 -2.08549753e-01 -3.52908552e-01\n",
      "  7.32000396e-02  3.28273028e-01 -2.03969300e-01 -1.09194338e-01\n",
      " -1.12924457e+00 -1.11254804e-01 -4.78182659e-02 -1.68835685e-01\n",
      "  1.50811002e-01 -4.64007318e-01  1.89302057e-01 -1.78319290e-01\n",
      " -1.85853302e-01 -1.64309502e-01 -3.99728775e-01 -1.23447232e-01\n",
      "  1.38419852e-01 -1.31852612e-01  4.83828247e-01 -3.81855547e-01\n",
      "  8.47710818e-02  6.68997923e-03 -6.08393490e-01 -7.59834871e-02\n",
      " -2.81721205e-01  2.28756145e-02 -2.08193064e-01  7.28734210e-03\n",
      " -6.70518875e-01  7.06601515e-02  1.14604048e-01  1.62248805e-01\n",
      " -1.65225253e-01 -2.76364893e-01 -3.54677916e-01  3.40030432e-01\n",
      "  1.15863137e-01  1.54078752e-01  2.29556095e-02  1.32522658e-01\n",
      " -2.05900997e-01  5.02279587e-02 -2.65349329e-01 -4.62971330e-01\n",
      "  2.56332308e-01 -2.48637348e-01 -2.37687230e-01  2.50408143e-01\n",
      "  6.45465404e-02  2.29217008e-01 -2.44621173e-01 -1.38524562e-01\n",
      "  1.69820189e-01  2.12403730e-01  3.61076742e-01 -7.60791004e-01\n",
      "  2.58800060e-01 -8.41582716e-02 -2.30949879e-01  2.75333732e-01\n",
      " -7.60203779e-01 -2.79579103e-01  1.50069430e-01 -7.75662065e-02\n",
      " -5.49281955e-01  2.86074191e-01 -3.10516685e-01  1.86816096e-01\n",
      "  1.34904668e-01 -3.19829494e-01 -1.36565164e-01  2.30258688e-01\n",
      "  1.76549688e-01 -3.62329245e-01 -4.05596852e-01 -6.44568741e-01\n",
      "  1.71366826e-01 -6.43218532e-02 -2.51317266e-02 -7.25932270e-02\n",
      " -1.62355751e-01  3.41505441e-03 -8.53067860e-02 -6.43044114e-02\n",
      "  5.72879612e-01  3.65874887e-01  1.91894189e-01  2.77558893e-01\n",
      " -3.64800036e-01 -6.71236694e-01  3.76426131e-01 -1.11212276e-01\n",
      "  2.20794231e-01 -4.17988598e-02  1.82915524e-01 -1.59917131e-01\n",
      "  2.64112890e-01  2.81188965e-01 -5.56346737e-02  6.24102028e-03\n",
      " -4.47905064e-02  3.14816713e-01 -8.10849071e-02 -5.56692481e-01\n",
      "  3.81190836e-01  6.45514548e-01 -6.47893071e-01  2.06797123e-01\n",
      "  2.84246951e-01  4.75072749e-02  1.48910478e-01 -3.98723669e-02\n",
      " -3.08847100e-01 -3.33522946e-01 -2.96874866e-02  9.30232480e-02\n",
      " -3.73763263e-01 -6.29983783e-01  9.31573391e-01  1.08625263e-01\n",
      "  1.40289620e-01 -1.79429278e-01  3.39242220e-01 -2.36468967e-02\n",
      " -2.70073682e-01 -2.64462382e-01  7.70990876e-03  1.08492352e-01\n",
      " -8.10151324e-02  6.13723397e-01 -1.08754963e-01 -6.27107024e-01\n",
      " -3.55354309e+00  1.84776023e-01  1.18620269e-01 -1.68236300e-01\n",
      "  3.32414985e-01 -1.95748404e-01  1.95787817e-01 -2.36268163e-01\n",
      " -5.01731515e-01  2.04408526e-01 -2.74796456e-01  6.27057031e-02\n",
      " -4.43759784e-02  3.52888465e-01 -1.86585620e-01  2.80188769e-01\n",
      "  5.36194205e-01 -5.59192955e-01 -3.40794384e-01  7.34437466e-01\n",
      "  3.54211718e-01 -7.08666921e-01 -7.73431063e-02  7.93896243e-02\n",
      "  5.40319681e-01  4.29466695e-01 -2.50322998e-01  1.05385028e-01\n",
      " -3.67768526e-01 -2.78022021e-01  4.24490184e-01 -4.68154609e-01\n",
      "  1.26690686e-01 -2.18399525e-01  3.70198399e-01  7.09574495e-04\n",
      "  1.07712306e-01 -1.01163618e-01 -3.20728511e-01 -4.83010948e-01\n",
      "  3.36647809e-01 -4.58630651e-01 -4.50068153e-02 -2.56195575e-01\n",
      "  7.42937326e-01 -2.03763783e-01 -9.43460092e-02 -1.94115549e-01\n",
      "  8.84205699e-02  2.42393374e-01  1.55170724e-01  1.06558621e-01\n",
      "  3.59630823e-01 -5.47334790e-01 -7.51818001e-01 -1.44100308e-01\n",
      "  6.08091533e-01  3.12004805e-01 -2.61164457e-02 -4.10072863e-01\n",
      "  3.31586480e-01 -7.94411078e-02 -4.38257873e-01  7.40874037e-02\n",
      " -1.83924764e-01 -2.36928031e-01 -6.53767943e-01 -3.45557600e-01\n",
      " -1.64903343e-01  1.00255422e-02  1.13131665e-01  3.54903549e-01\n",
      " -3.81633401e-01 -6.89206481e-01 -2.88485318e-01 -3.35531622e-01\n",
      "  1.87684715e-01 -5.44593446e-02  1.04083680e-01 -1.19981490e-01\n",
      " -1.29763335e-01 -6.67158425e-01  1.26362443e-02  4.78734821e-01\n",
      "  3.10376644e-01  8.40081796e-02  4.03398275e-01  3.86204809e-01\n",
      " -4.00398262e-02 -4.18960959e-01  7.82617927e-01  1.02314606e-01\n",
      "  2.00108156e-01  4.72879350e-01  8.91658962e-02 -3.36387873e-01\n",
      "  2.57181317e-01  2.39644334e-01 -1.64913125e-02  4.32833992e-02\n",
      " -2.44572744e-01  3.14885855e-01  1.57066017e-01  4.26511824e-01\n",
      " -6.51116222e-02  5.09361088e-01 -2.01886728e-01 -3.10715079e-01\n",
      "  3.42929929e-01  4.23021227e-01  4.40325439e-01 -6.04069233e-01\n",
      "  2.06835389e-01  1.67659283e-01  3.69055336e-03 -1.90059558e-01\n",
      "  2.63082415e-01  1.23259842e-01 -1.16497548e-02 -2.03727290e-01\n",
      "  5.95196009e-01  7.92463839e-01 -2.60099679e-01  4.35735941e-01\n",
      " -2.46954598e-02 -1.10254586e-01 -6.88186213e-02  1.93802446e-01\n",
      " -5.64760029e-01 -1.33259818e-01  2.64898241e-01 -3.63698453e-01\n",
      " -3.95652950e-01  4.65562373e-01  1.36604533e-01  4.87007380e-01\n",
      " -2.04551965e-02 -3.64480883e-01 -1.20320797e-01  1.59982935e-01\n",
      "  3.19653273e-01  7.59271801e-01 -2.73265541e-01 -1.72481731e-01\n",
      "  2.31373198e-02  3.52959484e-01 -1.80433258e-01  1.24341190e-01\n",
      " -2.02163428e-01  3.26833159e-01 -1.50522873e-01 -2.60185331e-01\n",
      " -2.94820875e-01 -4.04232204e-01 -2.70329020e-03 -7.17271194e-02\n",
      "  4.30113554e-01 -1.43446773e-01 -1.70105487e-01 -4.64918286e-01\n",
      " -8.55510980e-02  1.05546725e+00 -2.94317394e-01  2.86739796e-01\n",
      " -1.02266803e-01  1.00132847e+00  6.40327334e-02 -2.68307775e-01\n",
      " -1.12225205e-01  3.50928813e-01  1.60816312e-01  2.64089793e-01\n",
      "  4.81283396e-01 -5.98879576e-01 -3.43993120e-02 -3.91074270e-01\n",
      "  3.07253808e-01 -1.91718146e-01 -8.05241913e-02 -1.00183226e-01\n",
      "  2.72668034e-01 -4.24452424e-01 -2.95234919e-01 -3.11312199e-01\n",
      "  6.79990351e-02  6.57276139e-02 -1.75330728e-01 -6.16331212e-02\n",
      " -3.18591833e-01  1.10830933e-01 -5.90299785e-01  7.77235329e-02\n",
      " -2.91845679e-01 -5.65963052e-03 -6.59460723e-01 -5.02265692e-01\n",
      "  2.85009053e-02 -4.89767134e-01  2.78954893e-01  4.03658777e-01\n",
      "  2.24485070e-01  1.56027123e-01 -1.26647219e-01 -1.54058024e-01\n",
      " -3.15730393e-01 -1.48724109e-01 -2.02244192e-01  2.89037824e-01\n",
      " -3.22828293e-01  2.76100248e-01 -4.58716750e-01  5.57262625e-04\n",
      " -2.15704843e-01 -8.39608908e-03  4.82650906e-01 -5.50991297e-01\n",
      "  2.28299433e-03 -2.04828471e-01 -4.98371869e-01  8.37786421e-02\n",
      " -4.08193350e-01 -1.62751719e-01  6.09981418e-01  3.60087872e-01\n",
      " -3.43438894e-01 -4.15515333e-01 -3.50676030e-01  5.83399713e-01\n",
      " -4.31239188e-01 -8.34258124e-02 -6.73515081e-01 -3.77912134e-01\n",
      "  2.31959745e-01 -2.28545386e-02  8.61214995e-02  1.96264595e-01\n",
      " -1.51031673e-01 -1.02328494e-01  3.51480275e-01 -5.05662570e-03\n",
      " -3.15536886e-01 -5.16946554e-01 -3.68030638e-01 -1.93488687e-01\n",
      " -3.09600006e-03 -1.61428496e-01 -1.72648802e-01  7.67693341e-01\n",
      "  9.23114270e-03  3.47209841e-01 -1.97195306e-01 -9.35723260e-02\n",
      " -2.80806243e-01 -4.13164049e-01 -4.37387042e-02 -3.71329308e-01\n",
      " -2.22722173e-01 -2.06749678e-01 -1.04813375e-01 -6.64085150e-03\n",
      " -6.87364191e-02 -2.92400539e-01 -1.94280326e-01  6.84367359e-01\n",
      "  1.20638730e-02  7.01990873e-02  2.98752058e-02  2.40208909e-01\n",
      "  1.30105615e-02 -7.19744980e-01 -5.96419871e-02  2.96090484e-01\n",
      "  8.59593824e-02 -5.29885367e-02 -6.53884634e-02 -4.29951213e-02\n",
      "  3.40691626e-01 -7.94502437e-01  1.24763653e-01 -7.71764457e-01\n",
      " -4.07710113e-02 -1.14841953e-01 -4.40135717e-01 -2.17858315e-01\n",
      " -1.02702416e-01 -4.36638832e-01 -2.16825590e-01  3.64129931e-01\n",
      " -1.07986353e-01 -1.81584716e-01 -2.37978641e-02  1.56146988e-01\n",
      " -2.79035002e-01  6.04897618e-01 -5.68474978e-02  1.31680712e-01\n",
      "  6.87341273e-01 -1.52280733e-01  2.32078373e-01  8.49211439e-02\n",
      "  1.14538580e-01  4.32772577e-01  3.46103758e-01  8.72626528e-02\n",
      " -4.52213734e-01  3.05289984e-01  4.52938944e-01  1.47027792e-02\n",
      "  1.24119431e-01  4.92168128e-01 -4.36403632e-01 -7.09286869e-01\n",
      "  8.32251668e-01  5.99963546e-01 -7.16590464e-01 -1.50114715e-01\n",
      "  2.70669937e-01 -3.88350099e-01  1.74401820e-01 -1.01096062e-02\n",
      " -1.28420025e-01 -1.55701891e-01  3.99905026e-01  1.96200445e-01\n",
      "  4.74131331e-02  7.87693679e-01 -3.35052192e-01 -7.22194612e-01\n",
      " -3.09915394e-01  5.25099576e-01 -5.37065446e-01  3.92416358e-01\n",
      " -3.42190236e-01  4.28272337e-01  4.03054476e-01  1.24143742e-01\n",
      " -2.35258400e-01  6.10062122e-01 -1.67682678e-01  1.44261315e-01\n",
      "  3.92949402e-01 -5.64060137e-02  9.08412814e-01  1.81131929e-01\n",
      "  3.79863381e-01  4.22195941e-01 -3.98577154e-01  4.98751491e-01\n",
      "  6.03640735e-01 -1.96451068e-01  9.83083621e-02 -1.07407317e-01\n",
      "  3.52673411e-01  1.41854048e-01  3.63535345e-01  1.44757509e-01\n",
      "  1.00788027e-01  6.52689189e-02 -3.40776332e-02  2.68505484e-01\n",
      "  1.09751046e-01 -2.56845579e-02  4.32003587e-01 -8.19685698e-01\n",
      " -1.34493738e-01  3.02995771e-01  6.85415938e-02 -3.44825059e-01\n",
      " -1.73638314e-01  1.22350730e-01 -1.36691853e-01 -8.51399675e-02\n",
      "  7.55676478e-02 -2.76585490e-01  1.08812608e-01  6.97735131e-01\n",
      "  2.50504520e-02 -5.65557480e-01 -1.26359150e-01 -6.34588972e-02\n",
      "  1.63601503e-01 -3.24371494e-02 -4.90292788e-01 -2.26965681e-01\n",
      " -1.50497362e-01 -2.77905464e-01 -1.54533431e-01 -3.55665952e-01\n",
      "  1.52425751e-01 -3.81822675e-01  3.38268012e-01 -2.54093170e-01\n",
      "  1.17850997e-01  5.72201788e-01  2.93416411e-01 -4.45391946e-02\n",
      "  5.10702312e-01  2.04886466e-01  3.99249822e-01  1.13722950e-01\n",
      "  1.97678387e-01 -3.36653769e-01  3.37934010e-02  7.85382316e-02\n",
      " -1.79849342e-01 -3.29716295e-01  1.64167970e-01 -1.00516140e-01\n",
      " -1.42110407e-01 -7.10494220e-01  3.27731341e-01  6.16303921e-01\n",
      " -7.68818259e-01 -1.12264305e-01 -2.92118460e-01  3.02405834e-01\n",
      "  3.16616952e-01  2.95843989e-01 -6.71773702e-02  2.08888575e-01\n",
      " -9.71736982e-02 -6.50081858e-02 -2.05380976e-01  2.84524530e-01\n",
      " -1.24391228e-01  3.65164503e-02 -6.11127689e-02  4.29820925e-01\n",
      " -2.82577097e-01  9.44336876e-02  1.77202001e-01 -6.60669804e-02\n",
      " -2.61842936e-01  1.48973241e-01  2.21374258e-01  5.79254553e-02\n",
      " -4.12686735e-01 -5.16655482e-02 -2.39802040e-02 -3.87722582e-01\n",
      "  2.90982515e-01  2.22863048e-01  5.74937940e-01 -2.74304986e-01\n",
      "  1.62348956e-01 -1.71998277e-01  2.46380910e-01 -7.27872625e-02\n",
      "  2.17156410e-01  1.47578120e-03 -1.81989953e-01 -4.31060679e-02\n",
      "  3.20584536e-01 -1.13450512e-02  3.41157690e-02 -3.17991406e-01\n",
      "  1.60671532e-01 -1.42567664e-01  1.92496702e-01 -1.73886895e-01] [ 1.10438623e-01  2.38302276e-01 -2.36267582e-01  8.12103599e-02\n",
      "  2.75458600e-02 -6.37928694e-02  6.68456629e-02  8.15940440e-01\n",
      " -1.25137925e-01 -5.63501000e-01  1.13091402e-01 -4.64912474e-01\n",
      " -1.13324262e-01  4.57905263e-01 -2.92391986e-01  7.62485936e-02\n",
      "  2.30690911e-01 -3.27981412e-02 -1.71833858e-01  2.20573142e-01\n",
      " -4.51891392e-01 -3.33347172e-01 -1.40411109e-01  7.05409586e-01\n",
      "  1.97370872e-01 -1.57786056e-01 -1.93640336e-01  2.18743652e-01\n",
      " -3.37818176e-01 -2.48755112e-01  1.74807698e-01  3.88062060e-01\n",
      " -2.03481212e-01 -8.01663026e-02 -1.80177927e-01 -1.75149649e-01\n",
      " -1.18086718e-01  1.72024500e-02 -2.84632117e-01  9.16976109e-02\n",
      " -3.44021142e-01 -1.10443331e-01 -5.10421284e-02 -8.14212039e-02\n",
      " -1.04684569e-01 -3.79997164e-01  1.49827093e-01  2.04074178e-02\n",
      "  2.52674043e-01 -3.51608187e-01 -4.79505241e-01  9.92520973e-02\n",
      " -3.64236832e-02 -2.77852297e-01  2.31849760e-01  3.37727070e-01\n",
      " -5.65393209e-01 -3.39772195e-01 -4.02904421e-01 -2.86357909e-01\n",
      "  3.05695921e-01  1.70565382e-01 -6.88010827e-02 -5.46605468e-01\n",
      "  6.26297742e-02  4.77467358e-01  1.10179774e-01  3.60976994e-01\n",
      " -7.57740974e-01 -2.96036422e-01 -4.95570719e-01 -3.72978389e-01\n",
      " -1.25141174e-01 -5.14676392e-01 -8.64460096e-02 -1.99540898e-01\n",
      " -1.62724599e-01  1.71909425e-02 -2.37172857e-01 -2.81123787e-01\n",
      "  8.88545737e-02  4.80554760e-01 -1.44047573e-01  2.78175682e-01\n",
      " -1.77364990e-01  1.08203009e-01 -7.98477381e-02 -1.10547081e-01\n",
      " -1.72657490e-01  5.98814897e-02 -7.80933946e-02 -6.58234209e-02\n",
      "  1.20027550e-01  3.05148065e-01  1.81650847e-01 -4.43234965e-02\n",
      "  5.33507884e-01 -2.45794341e-01 -2.06252739e-01  5.19127429e-01\n",
      "  8.36206302e-02 -2.71700293e-01  3.65902744e-02  6.39322773e-02\n",
      " -2.35989258e-01 -9.88344029e-02  6.78335177e-03 -6.05133809e-02\n",
      "  9.27267075e-02  2.86889106e-01  2.73663253e-01 -4.13056184e-03\n",
      " -2.43168548e-01 -4.11589682e-01 -4.27936077e-01  2.96418726e-01\n",
      "  3.44657481e-01 -3.17015499e-01 -4.27022159e-01 -2.90686905e-01\n",
      "  1.64566785e-01  1.90484017e-01  3.05809975e-01  5.70398510e-01\n",
      " -1.33635730e-01 -1.46389022e-01  1.64417610e-01 -4.37184647e-02\n",
      " -1.21440433e-01 -4.16112810e-01 -5.94836175e-02  3.26300353e-01\n",
      "  2.14787871e-01 -6.96546361e-02 -1.78706259e-01  2.36351296e-01\n",
      "  3.36985439e-01 -5.14593720e-01 -8.07096601e-01  1.98076621e-01\n",
      "  1.43405214e-01 -3.57048541e-01  4.69523221e-01  1.39875323e-01\n",
      "  2.90293992e-01 -1.56257916e-02  2.06977412e-01  3.89671862e-01\n",
      "  9.91392136e-02 -3.73614252e-01  4.45765465e-01  1.29019454e-01\n",
      " -2.46765628e-01  1.75046213e-02 -4.07328606e-01  3.55546102e-02\n",
      " -4.20591801e-01  3.95162076e-01 -5.81605360e-02  5.47558248e-01\n",
      "  2.84155428e-01 -1.94167227e-01  7.31770024e-02  3.82867664e-01\n",
      " -1.74861893e-01  6.19753540e-01  7.44109228e-02  3.26489538e-01\n",
      " -9.21823084e-03  1.48739934e-01 -2.46259928e-01  1.82845667e-01\n",
      "  4.24466819e-01 -2.61990935e-01 -3.67155492e-01  9.32213105e-03\n",
      " -1.58131137e-01  4.57464188e-01 -1.80075213e-01 -1.02732182e-01\n",
      " -1.52344215e+00 -2.76488513e-01  6.82564825e-03 -4.76934500e-02\n",
      "  3.62921029e-01  7.08692195e-03  2.52698530e-02 -7.46498480e-02\n",
      "  8.89640860e-03 -3.43665369e-02 -4.08245325e-01 -2.55709559e-01\n",
      " -1.44996926e-01  6.71457406e-03  5.71396172e-01 -1.63403302e-01\n",
      "  6.50207177e-02 -1.71867326e-01 -4.62670743e-01 -1.92885324e-01\n",
      " -1.87860820e-02  2.60142356e-01 -7.62811676e-02  2.69969970e-01\n",
      " -1.72540650e-01  1.82909384e-01  1.38107941e-01  7.90222138e-02\n",
      "  2.10439518e-01  2.92602837e-01 -5.85622787e-01  1.18222415e-01\n",
      "  1.35066405e-01  3.10478419e-01 -6.41966611e-02  1.21498927e-01\n",
      "  1.24818096e-02 -1.62033692e-01 -2.62765646e-01 -4.60787833e-01\n",
      " -7.43444785e-02 -1.10459015e-01 -3.21129829e-01  3.89658719e-01\n",
      " -1.05906293e-01 -6.13282397e-02  4.52541225e-02  1.60529211e-01\n",
      " -2.17512548e-02  3.19598258e-01  1.43353298e-01 -5.46798825e-01\n",
      "  7.52067268e-01  1.23182192e-01 -3.16518635e-01 -1.09107688e-01\n",
      " -6.24738514e-01 -1.86665028e-01  2.03580290e-01  3.84492539e-02\n",
      " -7.15720236e-01  2.22213551e-01  7.35865682e-02  3.23929936e-01\n",
      "  2.32766829e-02 -7.67952576e-02 -6.56740144e-02  1.71077251e-01\n",
      "  2.42515907e-01 -3.45690817e-01 -5.94097197e-01 -5.40050387e-01\n",
      "  1.81336924e-01 -8.54210183e-02  4.50631306e-02  2.02895060e-01\n",
      " -1.25045791e-01  3.65814209e-01  1.13374509e-01  2.78987497e-01\n",
      "  4.33044970e-01  2.98465312e-01 -6.96285889e-02  4.79601890e-01\n",
      " -3.37226540e-01 -5.54487288e-01  5.57899773e-01  1.85723066e-01\n",
      "  5.36513934e-03  4.64129150e-02  7.36159310e-02 -1.82614729e-01\n",
      " -1.58244729e-01  2.46959418e-01 -4.16327327e-01  2.75300313e-02\n",
      "  1.48298129e-01  2.44918555e-01  9.27122601e-04 -1.09920524e-01\n",
      "  3.90371591e-01  6.70638502e-01 -5.38991868e-01  3.85237664e-01\n",
      "  4.00131159e-02 -1.46840140e-01  2.28837833e-01 -1.88709617e-01\n",
      " -5.08143604e-01 -3.04743826e-01 -7.64405057e-02  2.74134185e-02\n",
      " -6.61785156e-02 -2.77454555e-01  6.13588870e-01  3.56151536e-02\n",
      "  5.84188886e-02 -1.77716225e-01  1.30594105e-01 -1.96785405e-01\n",
      " -3.88861328e-01 -4.38897043e-01  3.28626893e-02  3.48241419e-01\n",
      " -3.59953374e-01  3.50218564e-01 -3.09634268e-01 -3.20082217e-01\n",
      " -3.02176046e+00  1.19813085e-01  3.08264732e-01 -3.88182670e-01\n",
      "  4.64121044e-01 -2.52232164e-01  7.98845291e-02 -2.98643202e-01\n",
      " -7.17497706e-01  3.46641429e-02  4.78143916e-02 -3.96477059e-02\n",
      "  1.11608379e-01  3.74540597e-01  1.52365074e-01 -1.55932993e-01\n",
      "  3.84639263e-01 -4.26919669e-01 -1.74580172e-01  5.58828294e-01\n",
      "  2.25900754e-01 -6.99983686e-02 -3.58793475e-02 -3.31772953e-01\n",
      "  4.65049535e-01  7.64548123e-01  7.10640326e-02 -1.93307295e-01\n",
      " -2.44867116e-01 -2.74202317e-01  3.23388577e-01 -1.96809739e-01\n",
      "  2.28714675e-01 -9.03172716e-02  4.10469145e-01 -1.99812502e-01\n",
      " -2.29232442e-02  8.91260058e-02  9.21888426e-02 -3.91717494e-01\n",
      "  2.42061391e-01 -4.69713598e-01 -1.68152705e-01 -1.33171156e-01\n",
      "  4.98596251e-01  4.33150902e-02 -9.55119953e-02 -4.38009799e-01\n",
      "  6.28503934e-02  3.99699032e-01  1.56510577e-01  1.76307396e-03\n",
      "  1.62762314e-01 -3.79600376e-01 -3.80813748e-01  8.96317735e-02\n",
      "  2.17949718e-01  4.39283609e-01 -2.25310430e-01 -4.62061226e-01\n",
      "  9.98650268e-02 -2.83625014e-02 -3.32199037e-01  3.25969040e-01\n",
      " -1.24129519e-01 -2.01743335e-01 -5.96602857e-01 -2.76066095e-01\n",
      "  9.81862769e-02 -1.99607745e-01 -5.56476377e-02  5.41969001e-01\n",
      " -2.59628445e-01 -8.21166396e-01 -2.42638916e-01 -7.07761049e-02\n",
      " -2.47347906e-01  7.45566040e-02 -6.05160408e-02 -3.35911602e-01\n",
      " -2.09715202e-01 -6.58907771e-01 -8.81321579e-02  1.90639466e-01\n",
      "  1.23534322e-01 -1.11596538e-02  3.39334942e-02  1.34645790e-01\n",
      " -4.18091528e-02 -2.47561499e-01  2.94536561e-01  1.12961031e-01\n",
      "  1.46105304e-01  3.21391135e-01 -1.17516425e-02 -1.86868146e-01\n",
      "  1.32525340e-01 -4.42903228e-02 -3.51768099e-02  2.94745266e-01\n",
      " -5.63029461e-02  1.73570365e-01  6.17111981e-01  2.07748413e-01\n",
      "  6.82284590e-03  5.84147036e-01 -6.82385266e-01 -1.51549324e-01\n",
      "  2.30038494e-01  3.06515247e-01  5.00854254e-01 -5.02473891e-01\n",
      "  3.26264173e-01  1.83194607e-01 -1.30443528e-01 -1.05175018e-01\n",
      "  4.53463405e-01  4.99193594e-02 -1.66517600e-01  1.26236584e-02\n",
      "  5.35555661e-01  5.75738728e-01 -3.82351696e-01 -3.24199408e-01\n",
      " -5.10904193e-01 -3.18840072e-02 -2.42587715e-01 -2.08521679e-01\n",
      " -1.11503266e-01  5.38203679e-02  5.39630830e-01 -7.35972449e-02\n",
      " -5.57361662e-01  4.40238208e-01  9.51166749e-02  3.35407406e-01\n",
      " -3.98100689e-02 -1.85318559e-01 -2.15987086e-01 -1.75042868e-01\n",
      "  1.14726439e-01  4.27689224e-01 -3.60912055e-01 -4.27085944e-02\n",
      " -1.84503332e-01  3.23808342e-01 -8.34439397e-02 -3.21838826e-01\n",
      "  1.42299235e-02  1.26395047e-01 -1.11313365e-01 -1.74960241e-01\n",
      "  3.51476632e-02 -2.33921215e-01 -8.12970251e-02  1.83011383e-01\n",
      "  5.74560106e-01 -2.12963238e-01 -2.43389294e-01 -2.35718891e-01\n",
      " -6.30069003e-02  5.49039483e-01 -1.91378638e-01 -1.69032682e-02\n",
      " -1.69697672e-01  3.65845472e-01  3.72951806e-01 -3.19539011e-01\n",
      " -2.37243190e-01  1.46559983e-01 -1.42345950e-01  3.85494471e-01\n",
      "  2.97357142e-01 -4.92204636e-01 -9.94632617e-02  9.26173553e-02\n",
      " -5.72090819e-02 -3.27108443e-01  5.15526459e-02  3.89597490e-02\n",
      "  2.94114766e-03 -5.66078246e-01 -2.10813999e-01 -2.45088696e-01\n",
      "  1.71572581e-01 -1.42015005e-02 -1.37697294e-01 -3.16381902e-02\n",
      "  1.37054576e-02  1.75687566e-01 -5.42656541e-01 -1.04591250e-01\n",
      " -2.52023906e-01 -1.55139297e-01 -7.31382966e-01 -2.68732160e-02\n",
      "  2.69427836e-01 -4.17983264e-01  2.16103345e-01  6.33532703e-01\n",
      "  3.96257341e-02  9.10662785e-02 -2.34226331e-01 -3.14606637e-01\n",
      " -4.98477519e-01 -4.35906984e-02 -4.23436403e-01  8.45879540e-02\n",
      " -6.19146883e-01  7.04466775e-02 -6.08377993e-01  7.76515007e-02\n",
      " -3.88645947e-01  5.05460277e-02  4.94351238e-01 -3.71412218e-01\n",
      "  3.41839552e-01 -7.20684901e-02 -3.14416170e-01  1.36628941e-01\n",
      " -1.83185577e-01 -4.29701000e-01  2.10306928e-01 -1.73165664e-01\n",
      " -2.72902280e-01 -6.32128596e-01 -1.12719350e-01  1.84788033e-01\n",
      " -3.41875941e-01  7.47445300e-02 -4.73803043e-01 -2.94065267e-01\n",
      "  1.71470210e-01 -1.14104338e-01  2.96137094e-01  2.46544868e-01\n",
      "  2.04823837e-01 -1.30555660e-01  7.71372095e-02  6.01577759e-02\n",
      "  9.63049605e-02 -3.76085453e-02 -1.76619798e-01  3.40154357e-02\n",
      "  5.05456805e-01 -5.78147210e-02  3.85140888e-02  4.41776216e-01\n",
      "  2.11658832e-02  3.28706831e-01 -1.42170101e-01  8.87117907e-02\n",
      " -3.37517977e-01 -2.99414814e-01 -1.60750747e-02 -6.66111052e-01\n",
      " -2.15516806e-01 -1.39121249e-01  6.97134957e-02  3.22756350e-01\n",
      " -1.42370567e-01 -1.57120183e-01  1.79631814e-01  6.16893470e-01\n",
      " -1.10601768e-01  2.57335424e-01  1.94075733e-01  3.34791869e-01\n",
      "  1.98006734e-01 -3.30223709e-01  5.31236231e-02  5.86078584e-01\n",
      "  5.71227912e-03 -1.42497495e-01 -1.91068754e-01  1.13023724e-02\n",
      " -7.79537484e-02 -5.74257791e-01 -4.05431949e-02 -5.58530986e-01\n",
      "  5.07265091e-01  1.79827556e-01 -2.05766320e-01 -5.43491304e-01\n",
      " -3.72317806e-02 -1.01079322e-01 -7.98777714e-02  5.52544534e-01\n",
      " -1.78886399e-01  2.07310200e-01 -9.41923037e-02  4.05756205e-01\n",
      "  5.60298329e-03 -1.23981260e-01  1.88860342e-01  1.88308749e-02\n",
      "  3.83107603e-01 -2.63323933e-01 -4.76940900e-01  1.05685368e-01\n",
      "  9.01801139e-02  2.34371081e-01  1.70447364e-01  9.12994668e-02\n",
      " -1.72756258e-02  2.28706166e-01  3.69940519e-01 -1.70992106e-01\n",
      "  2.44646370e-02  5.31495273e-01 -2.94876605e-01 -3.99981648e-01\n",
      "  4.92168963e-01  6.17509842e-01 -6.62080944e-01 -1.05032548e-01\n",
      " -9.16638821e-02 -2.39890113e-01  2.53987402e-01 -2.92936377e-02\n",
      "  3.23567003e-01 -2.98672616e-02  2.95516819e-01  1.43864557e-01\n",
      " -2.67815124e-02  1.95388511e-01 -5.43150306e-02 -6.30844533e-01\n",
      " -1.81365281e-01  5.81804097e-01 -3.43958229e-01  2.11051121e-01\n",
      " -1.70592710e-01  2.39299938e-01  8.74103606e-03 -3.92229110e-03\n",
      " -1.77633733e-01  3.72670650e-01 -3.80790122e-02  8.78855661e-02\n",
      " -5.09685352e-02  1.42204925e-01  8.28290761e-01  2.94791162e-01\n",
      "  4.67928320e-01  3.22936326e-01 -6.98362812e-02  5.61264217e-01\n",
      "  7.35308766e-01 -1.80590197e-01  2.18733519e-01  1.71471953e-01\n",
      "  8.49927887e-02  1.19803429e-01 -4.59692553e-02  2.81034913e-02\n",
      "  1.63856238e-01  2.52919793e-01  7.07208067e-02  2.98313767e-01\n",
      "  4.40431267e-01 -1.65387373e-02  8.52171332e-02 -6.14226222e-01\n",
      " -5.78644127e-03  4.49302373e-03  1.62228107e-01 -4.46525551e-02\n",
      " -2.58538406e-02 -3.49082291e-01  9.64069590e-02  2.76990712e-01\n",
      " -1.64906174e-01 -1.15475789e-01  1.89107522e-01  8.00757408e-01\n",
      "  3.26795846e-01 -1.42137647e-01  2.35986084e-01  7.28822574e-02\n",
      "  3.19195479e-01 -9.99240503e-02 -5.90023220e-01 -4.36782688e-01\n",
      "  1.45545334e-01 -3.11468571e-01 -3.32558341e-02 -3.17685872e-01\n",
      "  3.45384151e-01 -6.24081492e-01  2.02773735e-01 -2.97684252e-01\n",
      "  1.03491269e-01  4.42557871e-01  1.75636530e-01  2.16790110e-01\n",
      "  6.12135828e-01  4.84765381e-01  3.42037648e-01 -5.31587787e-02\n",
      "  4.55484241e-01 -4.19252068e-01  1.68153383e-02  1.60599560e-01\n",
      " -8.88748318e-02 -9.48339850e-02  1.05104819e-01 -1.13091215e-01\n",
      " -5.82674861e-01 -5.91445029e-01  8.92465189e-02  4.79007721e-01\n",
      " -1.13136744e+00  7.86189660e-02 -5.65234087e-02  2.21672028e-01\n",
      "  6.99124113e-02  1.66674241e-01 -3.60226721e-01  2.01505750e-01\n",
      " -1.81838796e-01 -1.49049252e-01  1.77246463e-02  5.39967358e-01\n",
      " -1.83321550e-01 -4.41339388e-02  9.85561237e-02  2.73746580e-01\n",
      " -1.31210953e-01 -3.81807983e-03  2.96674997e-01  5.09363180e-03\n",
      "  3.73333916e-02  1.53193131e-01  2.95736790e-01 -1.84866995e-01\n",
      " -3.08238059e-01 -2.16004491e-01 -4.09601212e-01 -5.01169801e-01\n",
      "  1.56460494e-01 -8.00568983e-02  6.44269168e-01 -1.26616433e-01\n",
      " -1.53384045e-01 -5.64400814e-02  1.80432811e-01 -1.94615275e-01\n",
      "  5.67138270e-02 -2.83228666e-01 -1.73977718e-01 -1.19240858e-01\n",
      "  3.42016697e-01 -9.80400965e-02  7.24394545e-02 -3.49473566e-01\n",
      "  2.22512558e-01 -3.01436990e-01 -1.71152011e-01 -1.51274890e-01]\n",
      "Cosine Similarity: 0.8057\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "trained = torch.load(r'C:\\Users\\Tairo Kageyama\\Documents\\GitHub\\Python-fo-Natural-Language-Processing-main\\lab5\\model\\S-BERT.pt')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.to(device)\n",
    "model.load_state_dict(trained)\n",
    "\n",
    "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = tokenizer(sentence_a, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    inputs_b = tokenizer(sentence_b, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids']\n",
    "    attention_a = inputs_a['attention_mask']\n",
    "    inputs_ids_b = inputs_b['input_ids']\n",
    "    attention_b = inputs_b['attention_mask']\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    print(u, v)\n",
    "    # print(u.reshape(1, -1), v.reshape(1, -1))\n",
    "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Syntactic = \"[CLS] fermat's last [MASK] [SEP]\"\n",
    "Semantic = \"[CLS] fermat's last theorem is among the most notable theorems in the history of [MASK] [SEP]\"\n",
    "\n",
    "Syntactic = tokenizer(Syntactic, padding='max_length', max_length=5, truncation=True)\n",
    "Semantic= tokenizer(Semantic, padding='max_length', max_length=16, truncation=True)\n",
    "\n",
    "\n",
    "# Syntactic_id = []\n",
    "# Semantic_id = []\n",
    "\n",
    "# for Sy in Syntatic:\n",
    "#     Syntactic_id.append(word2id[Sy])\n",
    "\n",
    "# for Se in Semantic:\n",
    "#     Semantic_id.append(word2id[Se])\n",
    "\n",
    "# print(type(Syntactic['input_ids']))\n",
    "# print(Semantic)\n",
    "\n",
    "input_syn = torch.tensor([Syntactic['input_ids']])\n",
    "input_sem = torch.tensor([Semantic['input_ids']])\n",
    "seg_syn = torch.tensor([Syntactic['token_type_ids']])\n",
    "seg_sem = torch.tensor([Semantic['token_type_ids']])\n",
    "mask_syn = torch.tensor([[3]])\n",
    "mask_sem = torch.tensor([[14]])\n",
    "att_syn = torch.tensor([Syntactic['attention_mask']])\n",
    "att_sem = torch.tensor([Semantic['attention_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of last hidden states: torch.Size([1, 18, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "text = \"Replace this text with your own sentence to predict its BERT embeddings.\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "trained = torch.load(r'C:\\Users\\Tairo Kageyama\\Documents\\GitHub\\Python-fo-Natural-Language-Processing-main\\lab5\\model\\S-BERT.pt')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.to(device)\n",
    "model.load_state_dict(trained)\n",
    "# logits_lm, logits_nsp = model(input_syn, seg_syn, mask_syn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(\"Shape of last hidden states:\", last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tokens: ['[unused241]', '[unused652]', '[unused687]', '[unused492]', '[unused632]']\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer, BertForMaskedLM\n",
    "# import torch\n",
    "\n",
    "# # BERTのトークナイザーを読み込む\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # テスト文を定義する\n",
    "# Syntactic = \"[CLS] fermat's last [MASK] [SEP]\"\n",
    "\n",
    "# # テキストをトークン化し、トークンIDに変換する\n",
    "# tokenized_text = tokenizer.tokenize(Syntactic)\n",
    "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# # マスクされたトークンの位置を特定する\n",
    "# masked_index = tokenized_text.index('[MASK]')\n",
    "\n",
    "# # トークンをテンソルに変換する\n",
    "# tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "# # BERTのモデルを読み込む\n",
    "# inputs = tokenizer(Syntactic, return_tensors='pt')\n",
    "# trained = torch.load(r'C:\\Users\\Tairo Kageyama\\Documents\\GitHub\\Python-fo-Natural-Language-Processing-main\\lab5\\model\\S-BERT.pt')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# model.to(device)\n",
    "# model.load_state_dict(trained)\n",
    "# model.eval()\n",
    "\n",
    "# # テキストをBERTモデルに入力して、マスクされたトークンを予測する\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(tokens_tensor)\n",
    "#     predictions = outputs[0][0, masked_index].topk(5)  # トップ5の予測を取得\n",
    "\n",
    "# # 予測されたトークンを出力する\n",
    "# predicted_tokens = tokenizer.convert_ids_to_tokens(predictions.indices.tolist())\n",
    "# print(\"Predicted tokens:\", predicted_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
